{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "from scipy.stats import pearsonr\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe the 50 dimensions is a little too small and I should start with 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('/home/mendu/Thesis/data/musiccaps/embedding_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your fine-tuned local model \n",
    "model_path = '/home/mendu/Thesis/data/musiccaps/embedding_model'\n",
    "model = SentenceTransformer(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# captions = pd.read_csv('/home/mendu/Thesis/data/musiccaps/lp-music-caps_caption_writing.csv', index_col = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "msd_dataset = load_dataset('seungheondoh/LP-MusicCaps-MSD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(msd_dataset['train'])\n",
    "# test = pd.DataFrame(msd_dataset['test'])\n",
    "# valid = pd.DataFrame(msd_dataset['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = train['caption_writing'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e6ee7baaba4855a0da0994d95d9a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/13903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate embeddings for your sentences using the fine-tuned model\n",
    "embedded_sentences = model.encode(sentences, show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "# Number of PCA components (e.g., reduce to 50 dimensions)\n",
    "num_components = 50\n",
    "obj = PCA(n_components=num_components)\n",
    "\n",
    "# Fit the PCA model to the embedded sentences (this will find the principal components)\n",
    "pca_embeddings = obj.fit_transform(embedded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Pearson's correlation: 0.9783669148960427\n"
     ]
    }
   ],
   "source": [
    "# Project the PCA embeddings back to the original space\n",
    "projected_embeddings = obj.inverse_transform(pca_embeddings)\n",
    "\n",
    "# Initialize an empty list to store the Pearson correlation coefficients\n",
    "pearsons_correlations = []\n",
    "\n",
    "# Calculate Pearson's correlation for each pair of original and projected embeddings\n",
    "for original, projected in zip(embedded_sentences, projected_embeddings):\n",
    "    # Compute Pearson's r\n",
    "    corr, _ = pearsonr(original, projected)\n",
    "    pearsons_correlations.append(corr)\n",
    "\n",
    "# If you want to compute a single Pearson's correlation coefficient for all data\n",
    "# Concatenate all embeddings and compute the correlation\n",
    "flat_original = embedded_sentences.flatten()\n",
    "flat_projected = projected_embeddings.flatten()\n",
    "overall_corr, _ = pearsonr(flat_original, flat_projected)\n",
    "\n",
    "# print(\"Pearsons correlation for each embedding pair:\", pearsons_correlations)\n",
    "print(\"Overall Pearson's correlation:\", overall_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original embeddings shape: (444865, 768)\n",
      "PCA-reduced embeddings shape: (444865, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original embeddings shape:\", embedded_sentences.shape)\n",
    "print(\"PCA-reduced embeddings shape:\", pca_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch import nn\n",
    "\n",
    "# class Autoencoder(nn.Module):\n",
    "#     def __init__(self, input_size, encoding_size):\n",
    "#         super(Autoencoder, self).__init__()\n",
    "#         # Encoder\n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Linear(input_size, encoding_size),\n",
    "#             nn.ReLU(True)\n",
    "#         )\n",
    "#         # Decoder\n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Linear(encoding_size, input_size),\n",
    "#             nn.Sigmoid()  # Using Sigmoid because embeddings are likely normalized\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         encoded = self.encoder(x)\n",
    "#         decoded = self.decoder(encoded)\n",
    "#         return decoded\n",
    "    \n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, encoding_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(256),  # Added batch normalization\n",
    "            nn.Linear(256, 128),  # Added another layer\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, encoding_size),  # Adjusted the size of the encoding layer\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_size, 128),  # Adjusted the size of the decoding layer\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 256),  # Added another layer\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(256),  # Added batch normalization\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, input_size),\n",
    "            nn.Sigmoid()  # Using Sigmoid because embeddings are likely normalized\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the NumPy array of embeddings to a PyTorch tensor\n",
    "embedded_sentences_tensor = torch.tensor(embedded_sentences, dtype=torch.float32)\n",
    "\n",
    "# Create a dataset and a dataloader\n",
    "dataset = TensorDataset(embedded_sentences_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the autoencoder\n",
    "input_size = embedded_sentences.shape[1]\n",
    "encoding_size = 50  # change this to whatever size you want to encode down to\n",
    "autoencoder = Autoencoder(input_size=input_size, encoding_size=encoding_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "criterion = nn.L1Loss()  # Binary Cross-Entropy Loss\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.33991751074790955\n",
      "Epoch 2/50, Loss: 0.33176615834236145\n",
      "Epoch 3/50, Loss: 0.3325769901275635\n",
      "Epoch 4/50, Loss: 0.3317558467388153\n",
      "Epoch 5/50, Loss: 0.3302921950817108\n",
      "Epoch 6/50, Loss: 0.330737829208374\n",
      "Epoch 7/50, Loss: 0.33267346024513245\n",
      "Epoch 8/50, Loss: 0.3308607041835785\n",
      "Epoch 9/50, Loss: 0.32729002833366394\n",
      "Epoch 10/50, Loss: 0.3311496675014496\n",
      "Epoch 11/50, Loss: 0.3295424282550812\n",
      "Epoch 12/50, Loss: 0.3310156464576721\n",
      "Epoch 13/50, Loss: 0.3272843360900879\n",
      "Epoch 14/50, Loss: 0.3283267021179199\n",
      "Epoch 15/50, Loss: 0.3254358768463135\n",
      "Epoch 16/50, Loss: 0.3255855143070221\n",
      "Epoch 17/50, Loss: 0.3274194300174713\n",
      "Epoch 18/50, Loss: 0.32612767815589905\n",
      "Epoch 19/50, Loss: 0.32675936818122864\n",
      "Epoch 20/50, Loss: 0.32734277844429016\n",
      "Epoch 21/50, Loss: 0.32455840706825256\n",
      "Epoch 22/50, Loss: 0.3268395960330963\n",
      "Epoch 23/50, Loss: 0.32459756731987\n",
      "Epoch 24/50, Loss: 0.32844969630241394\n",
      "Epoch 25/50, Loss: 0.3247191607952118\n",
      "Epoch 26/50, Loss: 0.32506895065307617\n",
      "Epoch 27/50, Loss: 0.3289819657802582\n",
      "Epoch 28/50, Loss: 0.3232881724834442\n",
      "Epoch 29/50, Loss: 0.3256389796733856\n",
      "Epoch 30/50, Loss: 0.32815077900886536\n",
      "Epoch 31/50, Loss: 0.32632169127464294\n",
      "Epoch 32/50, Loss: 0.3196205794811249\n",
      "Epoch 33/50, Loss: 0.32262927293777466\n",
      "Epoch 34/50, Loss: 0.3214874565601349\n",
      "Epoch 35/50, Loss: 0.3286935091018677\n",
      "Epoch 36/50, Loss: 0.32892200350761414\n",
      "Epoch 37/50, Loss: 0.3214240074157715\n",
      "Epoch 38/50, Loss: 0.3246072828769684\n",
      "Epoch 39/50, Loss: 0.32363182306289673\n",
      "Epoch 40/50, Loss: 0.3238585591316223\n",
      "Epoch 41/50, Loss: 0.324020653963089\n",
      "Epoch 42/50, Loss: 0.3229263722896576\n",
      "Epoch 43/50, Loss: 0.31996163725852966\n",
      "Epoch 44/50, Loss: 0.3201858103275299\n",
      "Epoch 45/50, Loss: 0.32706597447395325\n",
      "Epoch 46/50, Loss: 0.3230697214603424\n",
      "Epoch 47/50, Loss: 0.32120296359062195\n",
      "Epoch 48/50, Loss: 0.32418617606163025\n",
      "Epoch 49/50, Loss: 0.32371023297309875\n",
      "Epoch 50/50, Loss: 0.32694491744041443\n"
     ]
    }
   ],
   "source": [
    "epochs = 50  # Set this to the number of epochs to train for\n",
    "for epoch in range(epochs):\n",
    "    for data in dataloader:\n",
    "        inputs = data[0]\n",
    "        # Forward pass\n",
    "        outputs = autoencoder(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Pearson correlation: 0.784829393595392\n"
     ]
    }
   ],
   "source": [
    "# Switch the autoencoder to evaluation mode\n",
    "autoencoder.eval()\n",
    "\n",
    "# Process the entire dataset to obtain the decoded (projected) embeddings\n",
    "encoded_embeddings = autoencoder.encoder(embedded_sentences_tensor).detach().numpy()\n",
    "decoded_embeddings = autoencoder.decoder(torch.from_numpy(encoded_embeddings)).detach().numpy()\n",
    "\n",
    "# Calculate Pearson's correlation\n",
    "from scipy.stats import pearsonr\n",
    "correlations = np.array([pearsonr(original, decoded)[0] for original, decoded in zip(embedded_sentences, decoded_embeddings)])\n",
    "\n",
    "# print('Pearson correlation for each embedding pair:', correlations)\n",
    "print('Mean Pearson correlation:', np.mean(correlations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the metric, reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original embeddings shape: torch.Size([444865, 768])\n",
      "Entire dataset encoded embeddings shape: torch.Size([444865, 50])\n"
     ]
    }
   ],
   "source": [
    "print(\"Original embeddings shape:\", embedded_sentences_tensor.shape)\n",
    "\n",
    "# Switch autoencoder to evaluation mode\n",
    "autoencoder.eval()\n",
    "\n",
    "# Process the entire dataset to obtain the encoded embeddings\n",
    "encoded_embeddings = autoencoder.encoder(embedded_sentences_tensor).detach()\n",
    "\n",
    "print(\"Entire dataset encoded embeddings shape:\", encoded_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
