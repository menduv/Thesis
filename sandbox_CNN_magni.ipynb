{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 15:35:16.695246: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-28 15:35:16.806785: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-28 15:35:19.006185: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "# TODO:clean this\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "# from transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "import pyarrow.parquet as pa\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mp3_path</th>\n",
       "      <th>tags</th>\n",
       "      <th>caption_writing</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clip_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>american_bach_soloists-j_s__bach_solo_cantatas...</td>\n",
       "      <td>opera</td>\n",
       "      <td>Experience the majestic beauty of classical mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>american_bach_soloists-j_s__bach_solo_cantatas...</td>\n",
       "      <td>opera</td>\n",
       "      <td>Experience the rich sound of classical eleganc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>american_bach_soloists-j_s__bach_solo_cantatas...</td>\n",
       "      <td>opera</td>\n",
       "      <td>This powerful classic opera piece showcases th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>american_bach_soloists-j_s__bach_solo_cantatas...</td>\n",
       "      <td>opera</td>\n",
       "      <td>This atmospheric and introspective song blends...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lvx_nova-lvx_nova-01-contimune-30-59.mp3</td>\n",
       "      <td>electronic</td>\n",
       "      <td>This upbeat dance track features a pulsing tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58896</th>\n",
       "      <td>jacob_heringman-blame_not_my_lute-56-la_bressa...</td>\n",
       "      <td>classical</td>\n",
       "      <td>This classical guitar solo piece features intr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58897</th>\n",
       "      <td>jacob_heringman-blame_not_my_lute-56-la_bressa...</td>\n",
       "      <td>classical</td>\n",
       "      <td>This beautiful classical piece features a haun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58898</th>\n",
       "      <td>jacob_heringman-blame_not_my_lute-56-la_bressa...</td>\n",
       "      <td>classical</td>\n",
       "      <td>This classical piece features beautiful melodi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58907</th>\n",
       "      <td>jacob_heringman-blame_not_my_lute-57-lost_is_m...</td>\n",
       "      <td>classical</td>\n",
       "      <td>This beautiful classical piece features a gent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58915</th>\n",
       "      <td>jacob_heringman-blame_not_my_lute-58-a_toy_for...</td>\n",
       "      <td>classical</td>\n",
       "      <td>This beautiful classical guitar melody is slow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11826 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  mp3_path        tags  \\\n",
       "clip_id                                                                  \n",
       "2        american_bach_soloists-j_s__bach_solo_cantatas...       opera   \n",
       "6        american_bach_soloists-j_s__bach_solo_cantatas...       opera   \n",
       "10       american_bach_soloists-j_s__bach_solo_cantatas...       opera   \n",
       "11       american_bach_soloists-j_s__bach_solo_cantatas...       opera   \n",
       "14                lvx_nova-lvx_nova-01-contimune-30-59.mp3  electronic   \n",
       "...                                                    ...         ...   \n",
       "58896    jacob_heringman-blame_not_my_lute-56-la_bressa...   classical   \n",
       "58897    jacob_heringman-blame_not_my_lute-56-la_bressa...   classical   \n",
       "58898    jacob_heringman-blame_not_my_lute-56-la_bressa...   classical   \n",
       "58907    jacob_heringman-blame_not_my_lute-57-lost_is_m...   classical   \n",
       "58915    jacob_heringman-blame_not_my_lute-58-a_toy_for...   classical   \n",
       "\n",
       "                                           caption_writing  \n",
       "clip_id                                                     \n",
       "2        Experience the majestic beauty of classical mu...  \n",
       "6        Experience the rich sound of classical eleganc...  \n",
       "10       This powerful classic opera piece showcases th...  \n",
       "11       This atmospheric and introspective song blends...  \n",
       "14       This upbeat dance track features a pulsing tec...  \n",
       "...                                                    ...  \n",
       "58896    This classical guitar solo piece features intr...  \n",
       "58897    This beautiful classical piece features a haun...  \n",
       "58898    This classical piece features beautiful melodi...  \n",
       "58907    This beautiful classical piece features a gent...  \n",
       "58915    This beautiful classical guitar melody is slow...  \n",
       "\n",
       "[11826 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/mendu/Thesis/data/magnatagatune/saved_df_data/df_w_captions.csv', index_col = [0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Encoder class focusing only on the encoding part\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, encoding_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, encoding_size),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "# Define input and encoding sizes\n",
    "input_size = 768\n",
    "encoding_size = 64\n",
    "def load_encoder_state_dict(encoder, state_dict_path):\n",
    "    state_dict = torch.load(state_dict_path)\n",
    "    # Rename the state_dict keys to match the structure of the Encoder class\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        # Prepend 'layers.' to each key\n",
    "        name = f'layers.{k}'\n",
    "        new_state_dict[name] = v\n",
    "    \n",
    "    encoder.load_state_dict(new_state_dict)\n",
    "    return encoder\n",
    "\n",
    "def get_device():\n",
    "    return torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device = get_device()\n",
    "# Instantiate the encoder\n",
    "encoder = Encoder(input_size=input_size, encoding_size=encoding_size).to(device)\n",
    "encoder.eval()  # Set the encoder to evaluation mode\n",
    "\n",
    "# Load the pre-trained weights for the encoder\n",
    "encoder = load_encoder_state_dict(encoder, '/home/mendu/Thesis/data/musiccaps/auto_encoder/encoder_state_dict.pth')\n",
    "\n",
    "# Load the SentenceTransformer model and move to the correct device\n",
    "roberta_model = SentenceTransformer('/home/mendu/Thesis/data/musiccaps/new_embedding_model').to(device)\n",
    "\n",
    "# Assuming df is a predefined DataFrame with text data\n",
    "caption = df.caption_writing[2]\n",
    "# Function to encode caption\n",
    "def encode_caption(encoder, sentence_model, text):\n",
    "    with torch.no_grad():\n",
    "        encoded_caption = sentence_model.encode(text, convert_to_tensor=True)\n",
    "        encoded_caption = encoded_caption.to(device)\n",
    "        return encoder(encoded_caption.unsqueeze(0))\n",
    "    \n",
    "# Encoded caption\n",
    "fully_encoded_caption = encode_caption(encoder, roberta_model, caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 52.0009,  28.6403,  34.2275,  59.2607,   1.1570,  57.7524, 142.9124,\n",
       "          44.6702,  41.6169, 104.4225,  92.6284, 119.1738,  42.9483,  79.1854,\n",
       "         216.7657,  67.0605,  43.6379,  77.6768, 100.6521,  87.6473, 132.7112,\n",
       "         126.8025,  86.1116, 131.3719,  68.6272,  81.4069, 134.8302, 196.9826,\n",
       "          90.1404,  65.5783,  97.3774, 187.2035,  53.5716, 243.3475,   0.0000,\n",
       "           0.0000,  55.3763, 132.5184,  23.2223,   0.0000, 155.0516,  99.4067,\n",
       "          38.8811, 111.8058, 213.8127, 153.5288,   0.0000,  39.6156,  19.5320,\n",
       "         135.4064,  96.3223,  40.3084, 116.1382, 154.0468,  79.5539,  27.2223,\n",
       "          96.1176,  39.1434, 160.7672,  63.0411,  12.1961,  99.3322,  49.6889,\n",
       "          55.5985]], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fully_encoded_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mp3_path</th>\n",
       "      <th>tags</th>\n",
       "      <th>caption_writing</th>\n",
       "      <th>caption_embedding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clip_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>american_bach_soloists-j_s__bach_solo_cantatas...</td>\n",
       "      <td>opera</td>\n",
       "      <td>Experience the majestic beauty of classical mu...</td>\n",
       "      <td>[52.000892639160156, 28.640304565429688, 34.22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>american_bach_soloists-j_s__bach_solo_cantatas...</td>\n",
       "      <td>opera</td>\n",
       "      <td>Experience the rich sound of classical eleganc...</td>\n",
       "      <td>[41.24440002441406, 41.702205657958984, 49.210...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>american_bach_soloists-j_s__bach_solo_cantatas...</td>\n",
       "      <td>opera</td>\n",
       "      <td>This powerful classic opera piece showcases th...</td>\n",
       "      <td>[49.760990142822266, 39.03318786621094, 39.876...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>american_bach_soloists-j_s__bach_solo_cantatas...</td>\n",
       "      <td>opera</td>\n",
       "      <td>This atmospheric and introspective song blends...</td>\n",
       "      <td>[74.27188110351562, 52.33830261230469, 113.251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lvx_nova-lvx_nova-01-contimune-30-59.mp3</td>\n",
       "      <td>electronic</td>\n",
       "      <td>This upbeat dance track features a pulsing tec...</td>\n",
       "      <td>[37.00017547607422, 0.0, 132.0074920654297, 71...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58896</th>\n",
       "      <td>jacob_heringman-blame_not_my_lute-56-la_bressa...</td>\n",
       "      <td>classical</td>\n",
       "      <td>This classical guitar solo piece features intr...</td>\n",
       "      <td>[94.79190826416016, 0.0, 19.968608856201172, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58897</th>\n",
       "      <td>jacob_heringman-blame_not_my_lute-56-la_bressa...</td>\n",
       "      <td>classical</td>\n",
       "      <td>This beautiful classical piece features a haun...</td>\n",
       "      <td>[74.07515716552734, 20.25941276550293, 33.8745...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58898</th>\n",
       "      <td>jacob_heringman-blame_not_my_lute-56-la_bressa...</td>\n",
       "      <td>classical</td>\n",
       "      <td>This classical piece features beautiful melodi...</td>\n",
       "      <td>[76.3675308227539, 31.28574562072754, 26.47723...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58907</th>\n",
       "      <td>jacob_heringman-blame_not_my_lute-57-lost_is_m...</td>\n",
       "      <td>classical</td>\n",
       "      <td>This beautiful classical piece features a gent...</td>\n",
       "      <td>[77.44381713867188, 22.265329360961914, 31.762...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58915</th>\n",
       "      <td>jacob_heringman-blame_not_my_lute-58-a_toy_for...</td>\n",
       "      <td>classical</td>\n",
       "      <td>This beautiful classical guitar melody is slow...</td>\n",
       "      <td>[73.84481048583984, 28.320589065551758, 28.648...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11826 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  mp3_path        tags  \\\n",
       "clip_id                                                                  \n",
       "2        american_bach_soloists-j_s__bach_solo_cantatas...       opera   \n",
       "6        american_bach_soloists-j_s__bach_solo_cantatas...       opera   \n",
       "10       american_bach_soloists-j_s__bach_solo_cantatas...       opera   \n",
       "11       american_bach_soloists-j_s__bach_solo_cantatas...       opera   \n",
       "14                lvx_nova-lvx_nova-01-contimune-30-59.mp3  electronic   \n",
       "...                                                    ...         ...   \n",
       "58896    jacob_heringman-blame_not_my_lute-56-la_bressa...   classical   \n",
       "58897    jacob_heringman-blame_not_my_lute-56-la_bressa...   classical   \n",
       "58898    jacob_heringman-blame_not_my_lute-56-la_bressa...   classical   \n",
       "58907    jacob_heringman-blame_not_my_lute-57-lost_is_m...   classical   \n",
       "58915    jacob_heringman-blame_not_my_lute-58-a_toy_for...   classical   \n",
       "\n",
       "                                           caption_writing  \\\n",
       "clip_id                                                      \n",
       "2        Experience the majestic beauty of classical mu...   \n",
       "6        Experience the rich sound of classical eleganc...   \n",
       "10       This powerful classic opera piece showcases th...   \n",
       "11       This atmospheric and introspective song blends...   \n",
       "14       This upbeat dance track features a pulsing tec...   \n",
       "...                                                    ...   \n",
       "58896    This classical guitar solo piece features intr...   \n",
       "58897    This beautiful classical piece features a haun...   \n",
       "58898    This classical piece features beautiful melodi...   \n",
       "58907    This beautiful classical piece features a gent...   \n",
       "58915    This beautiful classical guitar melody is slow...   \n",
       "\n",
       "                                         caption_embedding  \n",
       "clip_id                                                     \n",
       "2        [52.000892639160156, 28.640304565429688, 34.22...  \n",
       "6        [41.24440002441406, 41.702205657958984, 49.210...  \n",
       "10       [49.760990142822266, 39.03318786621094, 39.876...  \n",
       "11       [74.27188110351562, 52.33830261230469, 113.251...  \n",
       "14       [37.00017547607422, 0.0, 132.0074920654297, 71...  \n",
       "...                                                    ...  \n",
       "58896    [94.79190826416016, 0.0, 19.968608856201172, 7...  \n",
       "58897    [74.07515716552734, 20.25941276550293, 33.8745...  \n",
       "58898    [76.3675308227539, 31.28574562072754, 26.47723...  \n",
       "58907    [77.44381713867188, 22.265329360961914, 31.762...  \n",
       "58915    [73.84481048583984, 28.320589065551758, 28.648...  \n",
       "\n",
       "[11826 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the encode_caption function to each row's caption_writing\n",
    "def get_encoded_caption(row):\n",
    "    caption = row['caption_writing']\n",
    "    return encode_caption(encoder, roberta_model, caption).cpu().clone().numpy().tolist()\n",
    "\n",
    "\n",
    "df['caption_embedding'] = df.apply(get_encoded_caption, axis=1)\n",
    "\n",
    "# Flatten the nested list\n",
    "df['caption_embedding'] = df['caption_embedding'].apply(lambda x: x[0])\n",
    "\n",
    "# Now df has an additional column with the caption embeddings as tensors\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mp3_path</th>\n",
       "      <th>tags</th>\n",
       "      <th>caption_writing</th>\n",
       "      <th>caption_embedding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clip_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>american_bach_soloists-j_s__bach_solo_cantatas...</td>\n",
       "      <td>opera</td>\n",
       "      <td>Experience the majestic beauty of classical mu...</td>\n",
       "      <td>[52.000892639160156, 28.640304565429688, 34.22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>american_bach_soloists-j_s__bach_solo_cantatas...</td>\n",
       "      <td>opera</td>\n",
       "      <td>Experience the rich sound of classical eleganc...</td>\n",
       "      <td>[41.24440002441406, 41.702205657958984, 49.210...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>american_bach_soloists-j_s__bach_solo_cantatas...</td>\n",
       "      <td>opera</td>\n",
       "      <td>This powerful classic opera piece showcases th...</td>\n",
       "      <td>[49.760990142822266, 39.03318786621094, 39.876...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>american_bach_soloists-j_s__bach_solo_cantatas...</td>\n",
       "      <td>opera</td>\n",
       "      <td>This atmospheric and introspective song blends...</td>\n",
       "      <td>[74.27188110351562, 52.33830261230469, 113.251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lvx_nova-lvx_nova-01-contimune-30-59.mp3</td>\n",
       "      <td>electronic</td>\n",
       "      <td>This upbeat dance track features a pulsing tec...</td>\n",
       "      <td>[37.00017547607422, 0.0, 132.0074920654297, 71...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58896</th>\n",
       "      <td>jacob_heringman-blame_not_my_lute-56-la_bressa...</td>\n",
       "      <td>classical</td>\n",
       "      <td>This classical guitar solo piece features intr...</td>\n",
       "      <td>[94.79190826416016, 0.0, 19.968608856201172, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58897</th>\n",
       "      <td>jacob_heringman-blame_not_my_lute-56-la_bressa...</td>\n",
       "      <td>classical</td>\n",
       "      <td>This beautiful classical piece features a haun...</td>\n",
       "      <td>[74.07515716552734, 20.25941276550293, 33.8745...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58898</th>\n",
       "      <td>jacob_heringman-blame_not_my_lute-56-la_bressa...</td>\n",
       "      <td>classical</td>\n",
       "      <td>This classical piece features beautiful melodi...</td>\n",
       "      <td>[76.3675308227539, 31.28574562072754, 26.47723...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58907</th>\n",
       "      <td>jacob_heringman-blame_not_my_lute-57-lost_is_m...</td>\n",
       "      <td>classical</td>\n",
       "      <td>This beautiful classical piece features a gent...</td>\n",
       "      <td>[77.44381713867188, 22.265329360961914, 31.762...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58915</th>\n",
       "      <td>jacob_heringman-blame_not_my_lute-58-a_toy_for...</td>\n",
       "      <td>classical</td>\n",
       "      <td>This beautiful classical guitar melody is slow...</td>\n",
       "      <td>[73.84481048583984, 28.320589065551758, 28.648...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11826 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  mp3_path        tags  \\\n",
       "clip_id                                                                  \n",
       "2        american_bach_soloists-j_s__bach_solo_cantatas...       opera   \n",
       "6        american_bach_soloists-j_s__bach_solo_cantatas...       opera   \n",
       "10       american_bach_soloists-j_s__bach_solo_cantatas...       opera   \n",
       "11       american_bach_soloists-j_s__bach_solo_cantatas...       opera   \n",
       "14                lvx_nova-lvx_nova-01-contimune-30-59.mp3  electronic   \n",
       "...                                                    ...         ...   \n",
       "58896    jacob_heringman-blame_not_my_lute-56-la_bressa...   classical   \n",
       "58897    jacob_heringman-blame_not_my_lute-56-la_bressa...   classical   \n",
       "58898    jacob_heringman-blame_not_my_lute-56-la_bressa...   classical   \n",
       "58907    jacob_heringman-blame_not_my_lute-57-lost_is_m...   classical   \n",
       "58915    jacob_heringman-blame_not_my_lute-58-a_toy_for...   classical   \n",
       "\n",
       "                                           caption_writing  \\\n",
       "clip_id                                                      \n",
       "2        Experience the majestic beauty of classical mu...   \n",
       "6        Experience the rich sound of classical eleganc...   \n",
       "10       This powerful classic opera piece showcases th...   \n",
       "11       This atmospheric and introspective song blends...   \n",
       "14       This upbeat dance track features a pulsing tec...   \n",
       "...                                                    ...   \n",
       "58896    This classical guitar solo piece features intr...   \n",
       "58897    This beautiful classical piece features a haun...   \n",
       "58898    This classical piece features beautiful melodi...   \n",
       "58907    This beautiful classical piece features a gent...   \n",
       "58915    This beautiful classical guitar melody is slow...   \n",
       "\n",
       "                                         caption_embedding  \n",
       "clip_id                                                     \n",
       "2        [52.000892639160156, 28.640304565429688, 34.22...  \n",
       "6        [41.24440002441406, 41.702205657958984, 49.210...  \n",
       "10       [49.760990142822266, 39.03318786621094, 39.876...  \n",
       "11       [74.27188110351562, 52.33830261230469, 113.251...  \n",
       "14       [37.00017547607422, 0.0, 132.0074920654297, 71...  \n",
       "...                                                    ...  \n",
       "58896    [94.79190826416016, 0.0, 19.968608856201172, 7...  \n",
       "58897    [74.07515716552734, 20.25941276550293, 33.8745...  \n",
       "58898    [76.3675308227539, 31.28574562072754, 26.47723...  \n",
       "58907    [77.44381713867188, 22.265329360961914, 31.762...  \n",
       "58915    [73.84481048583984, 28.320589065551758, 28.648...  \n",
       "\n",
       "[11826 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "# df.to_csv('/home/mendu/Thesis/data/magnatagatune/saved_df_data/df_w_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gauss_noise(image, mean = 0, var = 10):\n",
    "    '''function to add gaussian noise to an image'''\n",
    "    sigma = var ** 0.5\n",
    "\n",
    "    #creating a noise image with gaussian distribution\n",
    "    gaussian = np.random.normal(mean, sigma, (image.shape[0], image.shape[1]))\n",
    "\n",
    "    #creating a zeroes image\n",
    "    noisy_image = np.zeros(image.shape, np.float32)\n",
    "\n",
    "    #adding the noise to the original image\n",
    "    noisy_image = image + gaussian\n",
    "\n",
    "    #normalising the image\n",
    "    cv2.normalize(noisy_image, noisy_image, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
    "\n",
    "    #changing type\n",
    "    noisy_image = noisy_image.astype(np.uint8)\n",
    "\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the cropped .npy files in a tensor\n",
    "\n",
    "#the folder path to where the mel-specs are stored\n",
    "folder_path_mel = '/home/mendu/Thesis/data/magnatagatune/mel-specs'\n",
    "\n",
    "#The ordered list of all the filenames in the filtered_df\n",
    "audio_names_list = df[:500].mp3_path.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tags\n",
       "electronic    175\n",
       "rock           91\n",
       "classical      86\n",
       "indian         52\n",
       "opera          47\n",
       "new age        27\n",
       "pop            12\n",
       "country        10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:500].tags.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american_bach_soloists-j_s__bach_solo_cantatas-01-bwv54__i_aria-30-59.mp3\n",
      "american_bach_soloists-j_s__bach_solo_cantatas-01-bwv54__i_aria-146-175.mp3\n",
      "american_bach_soloists-j_s__bach_solo_cantatas-01-bwv54__i_aria-262-291.mp3\n",
      "american_bach_soloists-j_s__bach_solo_cantatas-01-bwv54__i_aria-291-320.mp3\n",
      "lvx_nova-lvx_nova-01-contimune-30-59.mp3\n",
      "american_bach_soloists-j_s__bach__cantatas_volume_v-01-gleichwie_der_regen_und_schnee_vom_himmel_fallt_bwv_18_i_sinfonia-117-146.mp3\n",
      "steven_devine-portrait_of_an_english_harpsichord-01-lesson_1_in_g_major_prelude_james_nares-30-59.mp3\n",
      "the_headroom_project-jetuton_andawai-01-linda_morena-88-117.mp3\n",
      "american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-30-59.mp3\n",
      "american_bach_soloists-heinrich_schutz__musicalische_exequien-01-musicalische_exequien_swv_279_teil_i_concert_in_form_einer_teutschen_begrabnismissa-146-175.mp3\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "i = 0\n",
    "\n",
    "for filename in audio_names_list: #iterates over the filtered_df audio names\n",
    "  filename_npy = str(filename[:-4]) + '.npy'\n",
    "  file_path = os.path.join(folder_path_mel, filename_npy) #creates a folder path for the mel_specs \n",
    "  img = np.load(file_path)\n",
    "  data.append(add_gauss_noise(img))\n",
    "\n",
    "  # To ensure that the files are getting loaded in the correct order\n",
    "  if i < 10 :\n",
    "    print(filename)\n",
    "  i = i+1\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caption Embeddings\n",
    "embeddings = (df['caption_embedding'][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.load('data/magnatagatune/data_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 128, 1255)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalize data\n",
    "data = data.astype('float32')/255.0\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to include the channel dimension\n",
    "data = data.reshape((-1, 128, 1255, 1))\n",
    "\n",
    "# Split data into training and validation sets\n",
    "# X_train, X_val, y_train, y_val = train_test_split(data, pd.get_dummies(df[:500]['tags']), test_size=0.1, random_state=42)\n",
    "# Split data into training and validation sets\n",
    "X_train_spec, X_val_spec, X_train_embed, X_val_embed, y_train, y_val = train_test_split(data, embeddings, pd.get_dummies(df[:500]['tags']), test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 128, 1255, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ImageDataGenerator with necessary augmentations\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2\n",
    ")\n",
    "\n",
    "datagen.fit(X_train_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define num_classes based on the number of unique genres\n",
    "num_classes = y_train.shape[1]\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 16:00:20.174645: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "class ModelSubClassing(keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # Layer of Block 1\n",
    "        self.conv1 = Conv2D(32, 3, strides=2, activation=\"relu\")\n",
    "        self.max1  = MaxPooling2D(3)\n",
    "        self.bn1   = BatchNormalization()\n",
    "\n",
    "        # Layer of Block 2\n",
    "        self.conv2 = Conv2D(64, 3, activation=\"relu\")\n",
    "        self.bn2   = BatchNormalization()\n",
    "        self.max2  = MaxPooling2D(3)\n",
    "        self.drop1 = Dropout(0.3)\n",
    "        \n",
    "        # Layer of Block 3\n",
    "        self.conv3 = Conv2D(128, 3, activation=\"relu\")\n",
    "        self.bn3   = BatchNormalization()\n",
    "        self.max3  = MaxPooling2D(3)\n",
    "        self.drop2 = Dropout(0.3)\n",
    "\n",
    "        # Flatten, followed by 3 dense layers: 128, 64, num_classes\n",
    "        self.flatten   = Flatten()\n",
    "        self.dense128 = Dense(128, activation=\"relu\")\n",
    "        self.dense64 = Dense(64, activation=\"relu\")\n",
    "        self.dense_out = Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # Unpack the inputs\n",
    "        mel_spectrogram, caption_embedding = inputs\n",
    "\n",
    "        # Forward pass: block 1\n",
    "        x = self.conv1(mel_spectrogram)\n",
    "        x = self.max1(x)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        # Forward pass: block 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.max2(x)\n",
    "        x = self.drop1(x, training=training)\n",
    "\n",
    "        # Forward pass: block 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.max3(x)\n",
    "        x = self.drop2(x, training=training)\n",
    "\n",
    "        # Flatten and dense layers\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense128(x)\n",
    "        x_dense64 = self.dense64(x)\n",
    "        y_hat = self.dense_out(x_dense64)\n",
    "        x_dense64_list = x_dense64.cpu().clone().numpy().tolist()\n",
    "        \n",
    "        return y_hat, x_dense64_list\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data\n",
    "        (mel_spectrogram, caption_embedding), y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred, x_dense64 = self((mel_spectrogram, caption_embedding), training=True)  # Forward pass\n",
    "            # Compute the standard loss value\n",
    "            loss = self.compiled_loss(y, y_pred)\n",
    "            # Add the custom loss component\n",
    "            custom_loss = tf.reduce_mean(tf.square(caption_embedding - x_dense64))\n",
    "            total_loss = loss + custom_loss\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(total_loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "# Example of using the custom model\n",
    "# num_classes = 10  # Example number of output classes\n",
    "model = ModelSubClassing(num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Create some dummy data\n",
    "# import numpy as np\n",
    "# X_mel = np.random.random((10, 128, 1255, 1))\n",
    "# X_caption = np.random.random((10, 64))\n",
    "# y = np.random.randint(0, num_classes, 10)\n",
    "\n",
    "# Train the model\n",
    "# model.fit((X_mel, X_caption), y, epochs=3, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m early_stopper \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopper\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# history = model.fit((X_train_spec, X_train_embed), y_train, epochs=..., batch_size=..., validation_data=((X_val_spec, X_val_embed), y_val), ...)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "# Use the early stopping callback to halt training if validation loss doesn't improve\n",
    "early_stopper = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    (X_train_spec, X_train_embed),\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=((X_val_spec, X_val_embed), y_val),\n",
    "    callbacks=[early_stopper]\n",
    ")\n",
    "\n",
    "# history = model.fit((X_train_spec, X_train_embed), y_train, epochs=..., batch_size=..., validation_data=((X_val_spec, X_val_embed), y_val), ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSubClassing(keras.Model):\n",
    "    def __init__(self, num_classes, dim):\n",
    "        super().__init__()\n",
    "        # define all layers in init\n",
    "        # Layer of Block 1\n",
    "        self.conv1 = keras.layers.Conv2D(\n",
    "                          32, 3, strides=2, activation=\"relu\"\n",
    "                     )\n",
    "        self.max1  = keras.layers.MaxPooling2D(3)\n",
    "        self.bn1   = keras.layers.BatchNormalization()\n",
    "\n",
    "        # Layer of Block 2\n",
    "        self.conv2 = keras.layers.Conv2D(64, 3, activation=\"relu\")\n",
    "        self.bn2   = keras.layers.BatchNormalization()\n",
    "        self.max2  = keras.layers.MaxPooling2D(3)\n",
    "        self.drop  = keras.layers.Dropout(0.3)\n",
    "        \n",
    "        # Layer of Block 3\n",
    "        self.conv3 = keras.layers.Conv2D(128, 3, activation=\"relu\")\n",
    "        self.bn3   = keras.layers.BatchNormalization()\n",
    "        self.max3  = keras.layers.MaxPooling2D(3)\n",
    "        self.drop  = keras.layers.Dropout(0.3)\n",
    "\n",
    "        # flatten, followed by 3 dense layers 128, 64, 8\n",
    "        self.flatten   = keras.layers.Flatten()\n",
    "        self.dense128 = keras.layers.Dense(128)\n",
    "        self.dense64 = keras.layers.Dense(64)\n",
    "        self.dense8 = keras.layers.Dense(num_classes)\n",
    "\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        # forward pass: block 1 \n",
    "        x = self.conv1(input_tensor)\n",
    "        x = self.max1(x)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        # forward pass: block 2 \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.max2(x)\n",
    "        \n",
    "        # forward pass: block 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.max3(x)\n",
    "\n",
    "        # droput followed by flatten and dense layers\n",
    "        x = self.drop(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense128(x)\n",
    "        x_dense64 = self.dense64(x)\n",
    "        y_hat = self.dense8(x_dense64)\n",
    "        return y_hat\n",
    "    \n",
    "    def build_graph(self):\n",
    "        x = Input(shape=(dim))\n",
    "        return Model(inputs=[x], outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = (128, 1255, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 10:32:31.527853: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/mendu/miniconda3/envs/myenv/lib/python3.11/site-packages/keras/src/layers/layer.py:359: UserWarning: `build()` was called on layer 'model_sub_classing', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1255</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">627</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">209</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">209</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">207</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">207</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2816</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">360,576</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1255\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m627\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m209\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m209\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m207\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m207\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m67\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m67\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2816\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m360,576\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m520\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">462,920</span> (1.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m462,920\u001b[0m (1.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">462,472</span> (1.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m462,472\u001b[0m (1.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_classing_model = ModelSubClassing(num_classes, dim)\n",
    "sub_classing_model.build((None, *dim))\n",
    "sub_classing_model.build_graph().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_classing_model.compile(\n",
    "          loss      = keras.losses.CategoricalCrossentropy(),\n",
    "          metrics   = ['accuracy'],\n",
    "          optimizer = keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For a model with multiple outputs, when providing the `metrics` argument as a list, it should have as many entries as the model has outputs. Received:\nmetrics=['accuracy']\nof length 1 whereas the model has 2 outputs.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# fit \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msub_classing_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/keras/src/trainers/compile_utils.py:251\u001b[0m, in \u001b[0;36mCompileMetrics._build_metrics_set\u001b[0;34m(self, metrics, num_outputs, output_names, y_true, y_pred, argument_name)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(metrics, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(metrics) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_pred):\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    252\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor a model with multiple outputs, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen providing the `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margument_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` argument as a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    254\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist, it should have as many entries as the model has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    255\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs. Received:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00margument_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mof \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(metrics)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m whereas the model has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(y_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m outputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m         )\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (mls, yt, yp) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mzip\u001b[39m(metrics, y_true, y_pred)\n\u001b[1;32m    261\u001b[0m     ):\n\u001b[1;32m    262\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mls, \u001b[38;5;28mlist\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: For a model with multiple outputs, when providing the `metrics` argument as a list, it should have as many entries as the model has outputs. Received:\nmetrics=['accuracy']\nof length 1 whereas the model has 2 outputs."
     ]
    }
   ],
   "source": [
    "# fit \n",
    "sub_classing_model.fit(X_train, y_train, batch_size=128, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a custom model class in Keras with the specified architecture and custom loss function, we need to incorporate the two inputs and custom loss into the train_step method. Here’s how you can define and train such a model:\n",
    "\n",
    "Define the model architecture to handle the two inputs.\n",
    "Implement the train_step method to compute the custom loss.\n",
    "Below is the complete implementation:\n",
    "\n",
    "Explanation:\n",
    "Model Architecture:\n",
    "\n",
    "The ModelSubClassing class defines the layers in the __init__ method.\n",
    "The call method specifies the forward pass using both inputs: the mel-spectrogram and the caption embedding.\n",
    "Custom Training Step:\n",
    "\n",
    "The train_step method is overridden to implement the custom loss function.\n",
    "The custom loss combines the standard classification loss with the MSE between the caption embedding and the output of the dense layer of size 64.\n",
    "Gradients are computed and applied to update the model’s weights.\n",
    "Compilation and Training:\n",
    "\n",
    "The model is compiled with an optimizer and loss function.\n",
    "The model is trained using dummy data to illustrate the usage. In practice, you would replace the dummy data with your actual dataset.\n",
    "This setup ensures that the model learns to minimize both the classification error and the difference between the caption embedding and the 64-dimensional dense layer output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense\n",
    "\n",
    "class ModelSubClassing(keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # Layer of Block 1\n",
    "        self.conv1 = Conv2D(32, 3, strides=2, activation=\"relu\")\n",
    "        self.max1  = MaxPooling2D(3)\n",
    "        self.bn1   = BatchNormalization()\n",
    "\n",
    "        # Layer of Block 2\n",
    "        self.conv2 = Conv2D(64, 3, activation=\"relu\")\n",
    "        self.bn2   = BatchNormalization()\n",
    "        self.max2  = MaxPooling2D(3)\n",
    "        self.drop1 = Dropout(0.3)\n",
    "        \n",
    "        # Layer of Block 3\n",
    "        self.conv3 = Conv2D(128, 3, activation=\"relu\")\n",
    "        self.bn3   = BatchNormalization()\n",
    "        self.max3  = MaxPooling2D(3)\n",
    "        self.drop2 = Dropout(0.3)\n",
    "\n",
    "        # Flatten, followed by 3 dense layers: 128, 64, num_classes\n",
    "        self.flatten   = Flatten()\n",
    "        self.dense128 = Dense(128, activation=\"relu\")\n",
    "        self.dense64 = Dense(64, activation=\"relu\")\n",
    "        self.dense_out = Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # Unpack the inputs\n",
    "        mel_spectrogram, caption_embedding = inputs\n",
    "\n",
    "        # Forward pass: block 1\n",
    "        x = self.conv1(mel_spectrogram)\n",
    "        x = self.max1(x)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        # Forward pass: block 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.max2(x)\n",
    "        x = self.drop1(x, training=training)\n",
    "\n",
    "        # Forward pass: block 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.max3(x)\n",
    "        x = self.drop2(x, training=training)\n",
    "\n",
    "        # Flatten and dense layers\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense128(x)\n",
    "        x_dense64 = self.dense64(x)\n",
    "        y_hat = self.dense_out(x_dense64)\n",
    "        \n",
    "        return y_hat, x_dense64\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data\n",
    "        (mel_spectrogram, caption_embedding), y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred, x_dense64 = self((mel_spectrogram, caption_embedding), training=True)  # Forward pass\n",
    "            # Compute the standard loss value\n",
    "            loss = self.compiled_loss(y, y_pred)\n",
    "            # Add the custom loss component\n",
    "            custom_loss = tf.reduce_mean(tf.square(caption_embedding - x_dense64))\n",
    "            total_loss = loss + custom_loss\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(total_loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "# Example of using the custom model\n",
    "num_classes = 10  # Example number of output classes\n",
    "model = ModelSubClassing(num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create some dummy data\n",
    "import numpy as np\n",
    "X_mel = np.random.random((10, 128, 1255, 1))\n",
    "X_caption = np.random.random((10, 64))\n",
    "y = np.random.randint(0, num_classes, 10)\n",
    "\n",
    "# Train the model\n",
    "model.fit((X_mel, X_caption), y, epochs=3, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D\n",
    "# from tensorflow.keras import Model\n",
    "\n",
    "# # Define a custom model class\n",
    "# class MyCustomModel(Model):\n",
    "#     def __init__(self):\n",
    "#         super(MyCustomModel, self).__init__()\n",
    "#         # Initialize layers\n",
    "#         self.conv1 = Conv2D(32, (3, 3), activation='relu')\n",
    "#         self.pool1 = MaxPooling2D((2, 2))\n",
    "#         self.conv2 = Conv2D(64, (3, 3), activation='relu')\n",
    "#         self.pool2 = MaxPooling2D((2, 2))\n",
    "#         self.flatten = Flatten()\n",
    "#         self.dense1 = Dense(128, activation='relu')\n",
    "#         self.dense2 = Dense(10, activation='softmax')\n",
    "    \n",
    "#     # Define the forward pass\n",
    "#     def call(self, inputs):\n",
    "#         x = self.conv1(inputs)\n",
    "#         x = self.pool1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.pool2(x)\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.dense1(x)\n",
    "#         return self.dense2(x)\n",
    "\n",
    "# # Instantiate the model\n",
    "# model = MyCustomModel()\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Print model summary (note that a summary can be printed only after the model is built)\n",
    "# input_shape = (None, 28, 28, 1)  # Example input shape\n",
    "# model.build(input_shape)\n",
    "# model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
